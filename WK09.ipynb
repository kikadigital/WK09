{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QshK8s21WBrf"
      },
      "source": [
        "# Week 09: Kattiana Theodore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hf8SXUwWOho"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Run the following 2 cells to import all necessary libraries and helpers for this week's exercises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -q https://github.com/DM-GY-9103-2024S-R/9103-utils/raw/main/src/io_utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import wave\n",
        "\n",
        "from IPython.display import Audio\n",
        "from PIL import Image\n",
        "\n",
        "from io_utils import wav_to_list, list_to_wav\n",
        "from io_utils import get_pixels, get_Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prKGt8bzScNA"
      },
      "source": [
        "## Digital Audio\n",
        "\n",
        "Air pressure waves converted to electrical pulses, which are then sampled and turned into a sequence of numbers.\n",
        "\n",
        "<img src=\"./imgs/audio-00.jpg\" width=\"720px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Playing an audio file\n",
        "\n",
        "Easy !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(Audio(\"./data/two-bits.wav\"))\n",
        "display(Audio(\"./data/horn.wav\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading an audio file for analysis, manipulation, etc\n",
        "\n",
        "is a bit more work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sound_file_path = \"./data/air-horn.wav\"\n",
        "with wave.open(sound_file_path, mode=\"rb\") as wav_in:\n",
        "  print(wav_in.getparams())\n",
        "\n",
        "display(Audio(sound_file_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Audio length, channels, samples, rate, depth\n",
        "\n",
        "<img src=\"./imgs/audio-01.jpg\" width=\"720px\">\n",
        "\n",
        "`Audio length`: The duration of an audio file in seconds.\n",
        "\n",
        "`Channels`: The different signals that make up an audio file.\n",
        "\n",
        "`Samples`: List of numbers that represent the quantized amplitude of an audio signal.\n",
        "\n",
        "`Frame`: Collection of samples from all channels at a given time. $Number\\ of\\ Frames = \\frac{Number\\ of\\ Samples}{Number\\ of\\ Channels}$\n",
        "\n",
        "`Sample Rate`: How many times per second the original audio signal was recorded. $Sample\\ Rate = \\frac{Number\\ of\\ Samples}{Audio\\ Length}$\n",
        "\n",
        "`Bit Depth` / `Sample Width`: How many different unique numbers are used to represent a sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Getting sample values\n",
        "\n",
        "We first have to open a `.wav` file with `wave.open()` to get a file object.\n",
        "\n",
        "We then use the file object `wav_in` to read the file's contents into a buffer of `bytes` with the `wav_in.readframes()` function.\n",
        "\n",
        "We use the `frombuffer()` function to turn `bytes` into `integers`.\n",
        "\n",
        "And, finally, we can use `list()` to put it all inside a regular Python list.\n",
        "\n",
        "<img src=\"./imgs/audio-02.jpg\" width=\"720px\">\n",
        "\n",
        "# 😫\n",
        "\n",
        "That's a lot of cryptic lines of code just to open a file and get a list of numbers !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sound_file_path = \"./data/western.wav\"\n",
        "with wave.open(sound_file_path, mode=\"rb\") as wav_in:\n",
        "  read_buffer = wav_in.readframes(wav_in.getnframes())\n",
        "  my_samples = list(np.frombuffer(read_buffer, dtype=np.int16))\n",
        "\n",
        "print(wav_in.getparams())\n",
        "print(\"length:\", wav_in.getnframes() / wav_in.getframerate())\n",
        "print(len(my_samples))\n",
        "print(my_samples[:16])\n",
        "print(min(my_samples), max(my_samples))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing\n",
        "\n",
        "At least we can visualize and play it from the list of samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(my_samples)\n",
        "plt.show()\n",
        "\n",
        "display(Audio(my_samples, rate=44100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 😫😫\n",
        "\n",
        "For sound files with more than one channel, the `Audio()` function expects the samples in a format that is different from the one returned by `wave.open()` and `wave.readframes()`.\n",
        "\n",
        "Argh!\n",
        "\n",
        "We can give `Audio()` every other sample to listen to just one of the channels:\n",
        "<br>`display(Audio(my_samples[::2], rate=44100))`\n",
        "\n",
        "But, it's better to use a function to read our wave files and return a single-channel array that combines all of the channels in an audio file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sound_file_path = \"./data/western.wav\"\n",
        "my_samples = wav_to_list(sound_file_path)\n",
        "\n",
        "print(len(my_samples))\n",
        "print(my_samples[:16])\n",
        "print(min(my_samples), max(my_samples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(my_samples)\n",
        "plt.show()\n",
        "\n",
        "display(Audio(my_samples, rate=44100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Manipulating\n",
        "\n",
        "Once we have a list of samples we can process, analyze and manipulate the audio by performing list operations and simple arithmetics.\n",
        "\n",
        "<img src=\"./imgs/audio-02.jpg\" width=\"720px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Change volume\n",
        "\n",
        "To change the volume of an audio file all we have to do is multiply its samples by a constant.\n",
        "\n",
        "If the constant is greater than $1$ it will get louder, if it's between $0$ and $1$ it will get softer.\n",
        "\n",
        "<img src=\"./imgs/audio-04.jpg\" width=\"720px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sound_file_path = \"./data/air-horn.wav\"\n",
        "my_samples = wav_to_list(sound_file_path)\n",
        "\n",
        "plt.plot(my_samples)\n",
        "plt.show()\n",
        "display(Audio(sound_file_path))\n",
        "\n",
        "changed_samples = []\n",
        "for s in my_samples:\n",
        "  changed_samples.append(int(s * 0.15))\n",
        "changed_samples[0] = 2**15-1\n",
        "\n",
        "plt.plot(changed_samples)\n",
        "plt.show()\n",
        "display(Audio(changed_samples, rate=44100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Change speed\n",
        "\n",
        "If we just duplicate each sample in our sequence, while keeping the sample rate the same, we'll end up with an audio file that is twice as long as the original.\n",
        "\n",
        "<img src=\"./imgs/audio-05.jpg\" width=\"720px\">\n",
        "\n",
        "And, conversely, if we remove every other sample, we'll get an audio signal that is half of the original length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sound_file_path = \"./data/horn.wav\"\n",
        "my_samples = wav_to_list(sound_file_path)\n",
        "\n",
        "plt.plot(my_samples)\n",
        "plt.show()\n",
        "display(Audio(sound_file_path))\n",
        "print(len(my_samples), \"samples\")\n",
        "\n",
        "double_samples = []\n",
        "for s in my_samples:\n",
        "  double_samples.append(s)\n",
        "  double_samples.append(s)\n",
        "\n",
        "plt.plot(double_samples)\n",
        "plt.show()\n",
        "display(Audio(double_samples, rate=44100))\n",
        "print(len(double_samples), \"samples\")\n",
        "\n",
        "half_samples = []\n",
        "for s in my_samples[::2]:\n",
        "  half_samples.append(s)\n",
        "\n",
        "plt.plot(half_samples)\n",
        "plt.show()\n",
        "display(Audio(half_samples, rate=44100))\n",
        "print(len(half_samples), \"samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reverse\n",
        "\n",
        "Flipping the order of the samples will make the audio sound backwards.\n",
        "\n",
        "<img src=\"./imgs/audio-06.jpg\" width=\"720px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sound_file_path = \"./data/two-bits.wav\"\n",
        "my_samples = wav_to_list(sound_file_path)\n",
        "\n",
        "plt.plot(my_samples)\n",
        "plt.show()\n",
        "display(Audio(sound_file_path))\n",
        "print(my_samples[:16])\n",
        "\n",
        "rev_samples = list(reversed(my_samples))\n",
        "\n",
        "plt.plot(rev_samples)\n",
        "plt.show()\n",
        "display(Audio(rev_samples, rate=44100))\n",
        "print(rev_samples[-16:])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Combining sounds\n",
        "\n",
        "To combine two audio signals, to have them play on top of each other, we just have to add every sample $S_{A_i}$ of our first audio file with it's corresponding sample in the second audio file $S_{B_i}$.\n",
        "\n",
        "<img src=\"./imgs/audio-07.jpg\" width=\"720px\">\n",
        "\n",
        "In this situation we can use the `zip()` function, which returns a sequence that is made up of pairs of elements from other sequences.\n",
        "\n",
        "For example, if we have:\n",
        "```python\n",
        "A = [10,11,12,13,14]\n",
        "B = [20,21,22,23,24]\n",
        "```\n",
        "\n",
        "then, `zip(A,B)` will give us this:\n",
        "```python\n",
        "[(10,20), (11,21), (12,22), (13,23), (14,24)]\n",
        "```\n",
        "\n",
        "It's like a zipper, where it builds its elements from one element of each of its arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "two_bit_file_path = \"./data/two-bits.wav\"\n",
        "two_bit_samples = wav_to_list(two_bit_file_path)\n",
        "\n",
        "air_horn_file_path = \"./data/air-horn.wav\"\n",
        "air_horn_samples = wav_to_list(air_horn_file_path)\n",
        "\n",
        "plt.plot(two_bit_samples)\n",
        "plt.show()\n",
        "display(Audio(two_bit_file_path))\n",
        "print(len(two_bit_samples), \"samples\")\n",
        "\n",
        "plt.plot(air_horn_samples)\n",
        "plt.show()\n",
        "display(Audio(air_horn_file_path))\n",
        "print(len(air_horn_samples), \"samples\")\n",
        "\n",
        "sum_samples = []\n",
        "for s0, s1 in zip(two_bit_samples, air_horn_samples):\n",
        "  sum_samples.append((s0 + s1) / 2)\n",
        "\n",
        "plt.plot(sum_samples)\n",
        "plt.show()\n",
        "display(Audio(sum_samples, rate=44100))\n",
        "print(len(sum_samples), \"samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Splicing\n",
        "\n",
        "Here we want to add the second wave after the first.\n",
        "\n",
        "In Python we can use addition to concatenate two lists:\n",
        "```python\n",
        "A = [0,1,2,3]\n",
        "B = [4,5,6,7]\n",
        "C = A + B\n",
        "```\n",
        "\n",
        "The `C` variable now holds `[0,1,2,3,4,5,6,7]`.\n",
        "\n",
        "We can also use slicing to select parts of the two sounds before adding them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "two_bit_file_path = \"./data/two-bits.wav\"\n",
        "two_bit_samples = wav_to_list(two_bit_file_path)\n",
        "\n",
        "air_horn_file_path = \"./data/air-horn.wav\"\n",
        "air_horn_samples = wav_to_list(air_horn_file_path)\n",
        "\n",
        "plt.plot(two_bit_samples)\n",
        "plt.show()\n",
        "display(Audio(two_bit_file_path))\n",
        "print(len(two_bit_samples), \"samples\")\n",
        "\n",
        "plt.plot(air_horn_samples)\n",
        "plt.show()\n",
        "display(Audio(air_horn_file_path))\n",
        "print(len(air_horn_samples), \"samples\")\n",
        "\n",
        "sum_samples = two_bit_samples + air_horn_samples\n",
        "\n",
        "plt.plot(sum_samples)\n",
        "plt.show()\n",
        "display(Audio(sum_samples, rate=44100))\n",
        "print(len(sum_samples), \"samples\")\n",
        "\n",
        "end_idx = int(0.6 * len(two_bit_samples))\n",
        "sum_samples = two_bit_samples[:end_idx] + air_horn_samples\n",
        "\n",
        "plt.plot(sum_samples)\n",
        "plt.show()\n",
        "display(Audio(sum_samples, rate=44100))\n",
        "print(len(sum_samples), \"samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Saving\n",
        "\n",
        "We can use the `list_to_wav()` function to save a sequence of samples to a mono `.wav` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_to_wav(sum_samples, \"out.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading image files\n",
        "\n",
        "We'll use the `Image` object from the [PIL](https://pillow.readthedocs.io/en/stable/) library to open image files.\n",
        "\n",
        "It's as simple as doing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L66UbgCWGDjF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "mimg = Image.open(\"./data/hog.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Image properties\n",
        "\n",
        "<img src=\"./imgs/image-00.jpg\" width=\"720px\">\n",
        "\n",
        "We can get some information about the image directly from this object.\n",
        "\n",
        "To get its dimensions, in pixels, we can access its `size` variable, which holds $2$ values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_width, image_height = mimg.size\n",
        "\n",
        "print(image_width, \"x\", image_height)\n",
        "print(\"total number of pixels:\", image_width * image_height)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And, to get the number of channels we can call its `getbands()` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "channel_count = len(mimg.getbands())\n",
        "\n",
        "print(channel_count, \"channels\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A note on channels\n",
        "\n",
        "Grayscale images have $1$ channel: each pixel holds a value between $0$ and $255$ that represents how bright that pixels is.\n",
        "\n",
        "RGB images have $3$ channels: each pixel is represented by $3$ values, one for each color red, green and blue.\n",
        "\n",
        "RGBA images have $4$ channels: each pixel has $3$ values for its RGB components, plus an extra one for transparency.\n",
        "\n",
        "<img src=\"./imgs/image-01.jpg\" width=\"720px\">\n",
        "\n",
        "This is important because when we get the list of pixels for an image we need to know what to expect from each of the list's members."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize the image\n",
        "\n",
        "We just have to call the built-in jupyter function `display()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(mimg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Getting pixel color lists\n",
        "\n",
        "We can also easily get a list of all the pixel color values by calling its `getdata()` member function and turning it into a `list`.\n",
        "\n",
        "This list has $width \\times height$ elements, one for each pixel on the image, and because this is an RGB image, each pixel element has $3$ values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_pixels = list(mimg.getdata())\n",
        "\n",
        "print(len(img_pixels))\n",
        "print(img_pixels[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Even though we view our images as two-dimensional arrangements of colors, in memory and in files, they're just long lists of numbers.\n",
        "\n",
        "<img src=\"./imgs/image-02.jpg\" width=\"720px\">\n",
        "\n",
        "And, just like with audio files, we can create or manipulate these lists before viewing them as images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating images from pixel color lists\n",
        "\n",
        "This is a bit trickier.\n",
        "\n",
        "We first have to create an empty image with a given size and specific number of channels, and then pass the list of pixel values to fill it in:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This creates an empty grayscale image with size 400 x 400\n",
        "rimg = Image.new(\"L\", (400, 400))\n",
        "\n",
        "# This fills a list with 400 * 400 random values between 0 and 255\n",
        "rpix_vals = []\n",
        "for i in range(400 * 400):\n",
        "  rpix_vals.append(random.randint(0, 255))\n",
        "\n",
        "# This puts the pixel values into the image object, so we can visualize it\n",
        "rimg.putdata(rpix_vals)\n",
        "display(rimg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Another example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This creates an empty RGB, 3-channel, image with size 400 x 400\n",
        "rimg = Image.new(\"RGB\", (400, 400))\n",
        "\n",
        "# This fills a list with 400 * 400 random RGB values\n",
        "rpix_vals = []\n",
        "for i in range(400 * 400):\n",
        "  r = random.randint(0, 255)\n",
        "  g = random.randint(0, 255)\n",
        "  b = random.randint(0, 255)\n",
        "  rpix_vals.append((r, g, b))\n",
        "\n",
        "# This puts the pixel values into the image object, so we can visualize it\n",
        "rimg.putdata(rpix_vals)\n",
        "display(rimg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 😵‍💫😖\n",
        "\n",
        "And, just like with audio files and sample lists, it's kind of annoying to always be turning pixels into images and images into pixels like this.\n",
        "\n",
        "Additionally, if the content of the pixel list passed to the function doesn't match the expected number of pixels or channels, the conversion will fail.\n",
        "\n",
        "Luckily, we can use some helper functions to make this easier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### To get pixel lists:\n",
        "`get_pixels(input)` : returns a list of pixel color values when given an `Image` object or the path to an image file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### To get `Image` objects:\n",
        "`get_Image(filepath)` : returns an `Image` object from the given file path.\n",
        "\n",
        "`get_Image(pixels, width, height)` : returns an `Image` object with size `width` $\\times$ `height` created from the values in the `pixels` list.\n",
        "\n",
        "We always have to specify at least the `width` value when creating an image from a pixel array, or else the function won't be able to know if we want an image that's $600 \\times 400$ or $400 \\times 600$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mimg = get_Image(\"./data/hog.jpg\")\n",
        "mpxs = get_pixels(\"./data/hog.jpg\")\n",
        "# or\n",
        "# mpxs = get_pixels(mimg)\n",
        "\n",
        "print(\"image size:\", mimg.size, \"pixel count:\", len(mpxs))\n",
        "print(\"first pixels:\", mpxs[0])\n",
        "\n",
        "display(mimg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Filtering by pixel\n",
        "\n",
        "We can create new images by changing the values of the pixels in our list.\n",
        "\n",
        "For example, if we want to separate the red component of our image, we can go through all of the pixel values and lower their green and blue components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "redpxs = []\n",
        "\n",
        "for r,g,b in mpxs:\n",
        "  redpxs.append((r, 0, 0))\n",
        "\n",
        "redimg = get_Image(redpxs, mimg.size[0], mimg.size[1])\n",
        "\n",
        "display(redimg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can exaggerate colors, by saturating a chosen channel in every pixel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "satpxs = []\n",
        "\n",
        "for r,g,b in mpxs:\n",
        "  if max(r,g,b) == g:\n",
        "    newg = int(min(255, 1.75 * g))\n",
        "    satpxs.append((r, newg, b))\n",
        "  else:\n",
        "    satpxs.append((r, g, b))\n",
        "\n",
        "satimg = get_Image(satpxs, mimg.size[0], mimg.size[1])\n",
        "\n",
        "display(satimg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also remove the colors by making all $3$ channels be equal to their average value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpxs = []\n",
        "\n",
        "for r,g,b in mpxs:\n",
        "  gval = (r + g + b) // 3\n",
        "  gpxs.append((gval, gval, gval))\n",
        "\n",
        "gimg = get_Image(gpxs, mimg.size[0], mimg.size[1])\n",
        "\n",
        "display(gimg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Saving\n",
        "\n",
        "To save an image file all we have to do is call the `.save()` function of an `Image` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gimg.save(\"gray-hog.jpg\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.17 ('hf-model')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
